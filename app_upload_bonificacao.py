import streamlit as st
import pandas as pd
import requests
from datetime import datetime, timedelta
from io import BytesIO
from msal import ConfidentialClientApplication
import unicodedata
import logging
import os
import json
import uuid
import time

# ===========================
# CONFIGURA√á√ïES DE VERS√ÉO - BONIFICA√á√ÉO v1.0.0
# ===========================
APP_VERSION = "1.0.0"
VERSION_DATE = "2025-10-03"
CHANGELOG = {
    "1.0.0": {
        "date": "2025-10-03",
        "changes": [
            "üéØ Sistema de consolida√ß√£o de bonifica√ß√µes",
            "üè™ Consolida√ß√£o por LOJA + M√äS/ANO",
            "üìÖ Campo DATA_ULTIMO_ENVIO por loja",
            "üé® Interface moderna e responsiva",
            "üîí Sistema de lock para m√∫ltiplos usu√°rios",
            "üíæ Backups autom√°ticos",
            "üõ°Ô∏è Valida√ß√£o rigorosa de datas",
            "üìä Dashboard com m√©tricas visuais"
        ]
    }
}

# ===========================
# ESTILOS CSS MELHORADOS
# ===========================
def aplicar_estilos_css():
    """Aplica estilos CSS customizados para melhorar a apar√™ncia"""
    st.markdown("""
    <style>
    /* Tema principal */
    :root {
        --primary-color: #2E8B57;
        --secondary-color: #20B2AA;
        --accent-color: #FFD700;
        --success-color: #32CD32;
        --warning-color: #FFA500;
        --error-color: #DC143C;
        --background-light: #F8F9FA;
        --text-dark: #2C3E50;
        --border-color: #E1E8ED;
    }
    
    /* Header principal */
    .main-header {
        background: linear-gradient(135deg, var(--primary-color), var(--secondary-color));
        padding: 2rem;
        border-radius: 15px;
        margin-bottom: 2rem;
        box-shadow: 0 4px 15px rgba(0,0,0,0.1);
        color: white;
    }
    
    .main-header h1 {
        margin: 0;
        font-size: 2.5rem;
        font-weight: 700;
        text-shadow: 2px 2px 4px rgba(0,0,0,0.3);
    }
    
    .version-badge {
        background: rgba(255,255,255,0.2);
        padding: 0.5rem 1rem;
        border-radius: 25px;
        font-size: 0.9rem;
        font-weight: 600;
        backdrop-filter: blur(10px);
    }
    
    /* Cards de status */
    .status-card {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
        border-left: 4px solid var(--primary-color);
        margin: 1rem 0;
        transition: transform 0.2s ease;
    }
    
    .status-card:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 20px rgba(0,0,0,0.12);
    }
    
    .status-card.success {
        border-left-color: var(--success-color);
        background: linear-gradient(135deg, #f0fff4, #ffffff);
    }
    
    .status-card.warning {
        border-left-color: var(--warning-color);
        background: linear-gradient(135deg, #fffaf0, #ffffff);
    }
    
    .status-card.error {
        border-left-color: var(--error-color);
        background: linear-gradient(135deg, #fff0f0, #ffffff);
    }
    
    /* M√©tricas melhoradas */
    .metric-container {
        background: white;
        padding: 1.5rem;
        border-radius: 12px;
        text-align: center;
        box-shadow: 0 2px 10px rgba(0,0,0,0.08);
        border-top: 3px solid var(--primary-color);
        transition: all 0.3s ease;
    }
    
    .metric-container:hover {
        transform: translateY(-3px);
        box-shadow: 0 6px 25px rgba(0,0,0,0.15);
    }
    
    .metric-value {
        font-size: 2.5rem;
        font-weight: 700;
        color: var(--primary-color);
        margin: 0.5rem 0;
    }
    
    .metric-label {
        font-size: 0.9rem;
        color: var(--text-dark);
        font-weight: 500;
        text-transform: uppercase;
        letter-spacing: 0.5px;
    }
    
    /* Bot√µes melhorados */
    .stButton > button {
        border-radius: 8px;
        font-weight: 600;
        transition: all 0.3s ease;
        border: none;
        box-shadow: 0 2px 8px rgba(0,0,0,0.1);
    }
    
    .stButton > button:hover {
        transform: translateY(-2px);
        box-shadow: 0 4px 15px rgba(0,0,0,0.2);
    }
    
    /* Progress bar customizada */
    .stProgress > div > div > div > div {
        background: linear-gradient(90deg, var(--primary-color), var(--secondary-color));
        border-radius: 10px;
    }
    
    /* Alertas customizados */
    .custom-alert {
        padding: 1rem 1.5rem;
        border-radius: 8px;
        margin: 1rem 0;
        border-left: 4px solid;
        font-weight: 500;
    }
    
    .custom-alert.info {
        background: #e3f2fd;
        border-left-color: #2196f3;
        color: #0d47a1;
    }
    
    .custom-alert.success {
        background: #e8f5e8;
        border-left-color: #4caf50;
        color: #1b5e20;
    }
    
    .custom-alert.warning {
        background: #fff3e0;
        border-left-color: #ff9800;
        color: #e65100;
    }
    
    .custom-alert.error {
        background: #ffebee;
        border-left-color: #f44336;
        color: #b71c1c;
    }
    
    /* Anima√ß√µes */
    @keyframes fadeIn {
        from { opacity: 0; transform: translateY(20px); }
        to { opacity: 1; transform: translateY(0); }
    }
    
    .fade-in {
        animation: fadeIn 0.6s ease-out;
    }
    
    /* Responsividade */
    @media (max-width: 768px) {
        .main-header h1 {
            font-size: 2rem;
        }
        
        .metric-value {
            font-size: 2rem;
        }
    }
    </style>
    """, unsafe_allow_html=True)

# ===========================
# CONFIGURA√á√ÉO DE LOGGING
# ===========================
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ===========================
# CREDENCIAIS VIA ST.SECRETS
# ===========================
try:
    CLIENT_ID = st.secrets["CLIENT_ID"]
    CLIENT_SECRET = st.secrets["CLIENT_SECRET"]
    TENANT_ID = st.secrets["TENANT_ID"]
    EMAIL_ONEDRIVE = st.secrets["EMAIL_ONEDRIVE"]
    SITE_ID = st.secrets["SITE_ID"]
    DRIVE_ID = st.secrets["DRIVE_ID"]
except KeyError as e:
    st.error(f"‚ùå Credencial n√£o encontrada: {e}")
    st.stop()

# ===========================
# CONFIGURA√á√ÉO DE PASTAS
# ===========================
PASTA_CONSOLIDADO = "Documentos Compartilhados/Bonificacao/FonteDeDados"
PASTA_ENVIOS_BACKUPS = "Documentos Compartilhados/PlanilhasEnviadas_Backups/Bonificacao"
PASTA = PASTA_CONSOLIDADO

# ===========================
# CONFIGURA√á√ÉO DO SISTEMA DE LOCK
# ===========================
ARQUIVO_LOCK = "sistema_lock_bonificacao.json"
TIMEOUT_LOCK_MINUTOS = 10

# ===========================
# AUTENTICA√á√ÉO
# ===========================
@st.cache_data(ttl=3300)
def obter_token():
    """Obt√©m token de acesso para Microsoft Graph API"""
    try:
        app = ConfidentialClientApplication(
            CLIENT_ID,
            authority=f"https://login.microsoftonline.com/{TENANT_ID}",
            client_credential=CLIENT_SECRET
        )
        result = app.acquire_token_for_client(scopes=["https://graph.microsoft.com/.default"])
        
        if "access_token" not in result:
            error_desc = result.get("error_description", "Token n√£o obtido")
            st.error(f"‚ùå Falha na autentica√ß√£o: {error_desc}")
            return None
            
        return result["access_token"]
        
    except Exception as e:
        st.error(f"‚ùå Erro na autentica√ß√£o: {str(e)}")
        logger.error(f"Erro de autentica√ß√£o: {e}")
        return None

# ===========================
# SISTEMA DE LOCK
# ===========================
def gerar_id_sessao():
    """Gera um ID √∫nico para a sess√£o atual"""
    if 'session_id' not in st.session_state:
        st.session_state.session_id = str(uuid.uuid4())[:8]
    return st.session_state.session_id

def verificar_lock_existente(token):
    """Verifica se existe um lock ativo no sistema"""
    try:
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            lock_data = response.json()
            timestamp_lock = datetime.fromisoformat(lock_data['timestamp'])
            agora = datetime.now()
            
            if agora - timestamp_lock > timedelta(minutes=TIMEOUT_LOCK_MINUTOS):
                logger.info(f"Lock expirado removido automaticamente. Era de {timestamp_lock}")
                remover_lock(token, force=True)
                return False, None
            
            return True, lock_data
        
        elif response.status_code == 404:
            return False, None
        else:
            logger.warning(f"Erro ao verificar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao verificar lock: {e}")
        return False, None

def criar_lock(token, operacao="Consolida√ß√£o de bonifica√ß√µes"):
    """Cria um lock para bloquear outras opera√ß√µes"""
    try:
        session_id = gerar_id_sessao()
        
        lock_data = {
            "timestamp": datetime.now().isoformat(),
            "session_id": session_id,
            "operacao": operacao,
            "status": "EM_ANDAMENTO",
            "app_version": APP_VERSION
        }
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        
        if response.status_code in [200, 201]:
            logger.info(f"Lock criado com sucesso. Session ID: {session_id}")
            return True, session_id
        else:
            logger.error(f"Erro ao criar lock: {response.status_code}")
            return False, None
            
    except Exception as e:
        logger.error(f"Erro ao criar lock: {e}")
        return False, None

def remover_lock(token, session_id=None, force=False):
    """Remove o lock do sistema"""
    try:
        if not force and session_id:
            lock_existe, lock_data = verificar_lock_existente(token)
            if lock_existe and lock_data.get('session_id') != session_id:
                logger.warning("Tentativa de remover lock de outra sess√£o!")
                return False
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.delete(url, headers=headers)
        
        if response.status_code in [200, 204]:
            logger.info("Lock removido com sucesso")
            return True
        elif response.status_code == 404:
            return True
        else:
            logger.error(f"Erro ao remover lock: {response.status_code}")
            return False
            
    except Exception as e:
        logger.error(f"Erro ao remover lock: {e}")
        return False

def atualizar_status_lock(token, session_id, novo_status, detalhes=None):
    """Atualiza o status do lock durante o processo"""
    try:
        lock_existe, lock_data = verificar_lock_existente(token)
        
        if not lock_existe or lock_data.get('session_id') != session_id:
            logger.warning("Lock n√£o existe ou n√£o pertence a esta sess√£o")
            return False
        
        lock_data['status'] = novo_status
        lock_data['ultima_atualizacao'] = datetime.now().isoformat()
        
        if detalhes:
            lock_data['detalhes'] = detalhes
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{ARQUIVO_LOCK}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/json"
        }
        
        response = requests.put(url, headers=headers, data=json.dumps(lock_data))
        return response.status_code in [200, 201]
        
    except Exception as e:
        logger.error(f"Erro ao atualizar status do lock: {e}")
        return False

def exibir_status_sistema(token):
    """Exibe o status atual do sistema de lock"""
    lock_existe, lock_data = verificar_lock_existente(token)
    
    if lock_existe:
        timestamp_inicio = datetime.fromisoformat(lock_data['timestamp'])
        duracao = datetime.now() - timestamp_inicio
        
        st.markdown("""
        <div class="status-card error">
            <h3>üîí Sistema Ocupado</h3>
            <p>Outro usu√°rio est√° enviando dados no momento</p>
        </div>
        """, unsafe_allow_html=True)
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{int(duracao.total_seconds()//60)}</div>
                <div class="metric-label">Minutos Ativo</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            tempo_limite = timestamp_inicio + timedelta(minutes=TIMEOUT_LOCK_MINUTOS)
            tempo_restante = tempo_limite - datetime.now()
            minutos_restantes = max(0, int(tempo_restante.total_seconds()//60))
            
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{minutos_restantes}</div>
                <div class="metric-label">Min. Restantes</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            status_display = lock_data.get('status', 'N/A')
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-label">Status</div>
                <div style="font-size: 1.2rem; font-weight: 600; color: var(--warning-color);">{status_display}</div>
            </div>
            """, unsafe_allow_html=True)
        
        with st.expander("‚ÑπÔ∏è Detalhes do processo em andamento"):
            col1, col2 = st.columns(2)
            
            with col1:
                st.info(f"**Opera√ß√£o:** {lock_data.get('operacao', 'N/A')}")
                st.info(f"**In√≠cio:** {timestamp_inicio.strftime('%H:%M:%S')}")
                
            with col2:
                if 'detalhes' in lock_data:
                    st.info(f"**Detalhes:** {lock_data['detalhes']}")
                    
                session_id_display = lock_data.get('session_id', 'N/A')[:8]
                st.caption(f"Session ID: {session_id_display}")
        
        if tempo_restante.total_seconds() < 0:
            if st.button("üÜò Liberar Sistema (For√ßar)", type="secondary"):
                if remover_lock(token, force=True):
                    st.success("‚úÖ Sistema liberado com sucesso!")
                    st.rerun()
                else:
                    st.error("‚ùå Erro ao liberar sistema")
        
        return True
    else:
        st.markdown("""
        <div class="status-card success">
            <h3>‚úÖ Sistema Dispon√≠vel</h3>
            <p>Voc√™ pode enviar sua planilha agora</p>
        </div>
        """, unsafe_allow_html=True)
        return False

# ===========================
# FUN√á√ïES AUXILIARES
# ===========================
def criar_pasta_se_nao_existir(caminho_pasta, token):
    """Cria pasta no OneDrive se n√£o existir"""
    try:
        partes = caminho_pasta.split('/')
        caminho_atual = ""
        
        for parte in partes:
            if not parte:
                continue
                
            caminho_anterior = caminho_atual
            caminho_atual = f"{caminho_atual}/{parte}" if caminho_atual else parte
            
            url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{caminho_atual}"
            headers = {"Authorization": f"Bearer {token}"}
            response = requests.get(url, headers=headers)
            
            if response.status_code == 404:
                parent_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root"
                if caminho_anterior:
                    parent_url += f":/{caminho_anterior}"
                parent_url += ":/children"
                
                create_body = {
                    "name": parte,
                    "folder": {},
                    "@microsoft.graph.conflictBehavior": "rename"
                }
                
                create_response = requests.post(
                    parent_url, 
                    headers={**headers, "Content-Type": "application/json"}, 
                    json=create_body
                )
                
                if create_response.status_code not in [200, 201]:
                    logger.warning(f"N√£o foi poss√≠vel criar pasta {parte}")
                    
    except Exception as e:
        logger.warning(f"Erro ao criar estrutura de pastas: {e}")

def upload_onedrive(nome_arquivo, conteudo_arquivo, token, tipo_arquivo="consolidado"):
    """Faz upload de arquivo para OneDrive"""
    try:
        if tipo_arquivo == "consolidado":
            pasta_base = PASTA_CONSOLIDADO
        elif tipo_arquivo in ["enviado", "backup"]:
            pasta_base = PASTA_ENVIOS_BACKUPS
        else:
            pasta_base = PASTA_CONSOLIDADO
        
        pasta_arquivo = "/".join(nome_arquivo.split("/")[:-1]) if "/" in nome_arquivo else ""
        if pasta_arquivo:
            criar_pasta_se_nao_existir(f"{pasta_base}/{pasta_arquivo}", token)
        
        if tipo_arquivo == "consolidado" and "/" not in nome_arquivo:
            mover_arquivo_existente(nome_arquivo, token, pasta_base)
        
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}:/content"
        headers = {
            "Authorization": f"Bearer {token}",
            "Content-Type": "application/octet-stream"
        }
        response = requests.put(url, headers=headers, data=conteudo_arquivo)
        
        return response.status_code in [200, 201], response.status_code, response.text
        
    except Exception as e:
        logger.error(f"Erro no upload: {e}")
        return False, 500, f"Erro interno: {str(e)}"

def mover_arquivo_existente(nome_arquivo, token, pasta_base=None):
    """Move arquivo existente para backup antes de substituir"""
    try:
        if pasta_base is None:
            pasta_base = PASTA_CONSOLIDADO
            
        url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{pasta_base}/{nome_arquivo}"
        headers = {"Authorization": f"Bearer {token}"}
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            file_id = response.json().get("id")
            timestamp = datetime.now().strftime("%Y-%m-%d_%Hh%M")
            nome_base = nome_arquivo.replace(".xlsx", "")
            novo_nome = f"{nome_base}_backup_{timestamp}.xlsx"
            
            patch_url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/items/{file_id}"
            patch_body = {"name": novo_nome}
            patch_headers = {
                "Authorization": f"Bearer {token}",
                "Content-Type": "application/json"
            }
            patch_response = requests.patch(patch_url, headers=patch_headers, json=patch_body)
            
            if patch_response.status_code in [200, 201]:
                st.info(f"üíæ Backup criado: {novo_nome}")
            else:
                st.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel criar backup do arquivo existente")
                
    except Exception as e:
        st.warning(f"‚ö†Ô∏è Erro ao processar backup: {str(e)}")
        logger.error(f"Erro no backup: {e}")

# ===========================
# VALIDA√á√ÉO DE DATAS
# ===========================
def validar_datas_detalhadamente(df):
    """Valida√ß√£o detalhada de datas"""
    problemas = []
    
    logger.info(f"üîç Iniciando valida√ß√£o detalhada de {len(df)} registros...")
    
    for idx, row in df.iterrows():
        linha_excel = idx + 2
        valor_original = row["DATA"]
        loja = row.get("LOJA", "N/A")
        
        problema_encontrado = None
        tipo_problema = None
        
        if pd.isna(valor_original) or str(valor_original).strip() == "":
            problema_encontrado = "Data vazia ou nula"
            tipo_problema = "VAZIO"
        else:
            try:
                data_convertida = pd.to_datetime(valor_original, errors='raise')
                hoje = datetime.now()
                
                if data_convertida > hoje + pd.Timedelta(days=730):
                    problema_encontrado = f"Data muito distante no futuro: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                elif data_convertida < pd.Timestamp('2020-01-01'):
                    problema_encontrado = f"Data muito antiga: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "ANTIGA"
                elif data_convertida > hoje:
                    problema_encontrado = f"Data no futuro: {data_convertida.strftime('%d/%m/%Y')}"
                    tipo_problema = "FUTURO"
                    
            except (ValueError, TypeError, pd.errors.OutOfBoundsDatetime) as e:
                if "day is out of range for month" in str(e) or "month must be in 1..12" in str(e):
                    problema_encontrado = f"Data imposs√≠vel: {valor_original}"
                    tipo_problema = "IMPOSS√çVEL"
                else:
                    problema_encontrado = f"Formato inv√°lido: {valor_original}"
                    tipo_problema = "FORMATO"
        
        if problema_encontrado:
            problemas.append({
                "Linha Excel": linha_excel,
                "Loja": loja,
                "Valor Original": valor_original,
                "Problema": problema_encontrado,
                "Tipo Problema": tipo_problema
            })
            
            logger.warning(f"‚ùå Linha {linha_excel}: {problema_encontrado} (Loja: {loja})")
    
    if problemas:
        logger.error(f"‚ùå TOTAL DE PROBLEMAS ENCONTRADOS: {len(problemas)}")
    else:
        logger.info("‚úÖ Todas as datas est√£o v√°lidas!")
    
    return problemas

def exibir_problemas_datas(problemas_datas):
    """Exibe problemas de datas com visual melhorado"""
    if not problemas_datas:
        return
    
    st.markdown("""
    <div class="custom-alert error">
        <h4>‚ùå Problemas de Data Encontrados</h4>
        <p>√â obrigat√≥rio corrigir TODOS os problemas antes de enviar</p>
    </div>
    """, unsafe_allow_html=True)
    
    tipos_problema = {}
    for problema in problemas_datas:
        tipo = problema["Tipo Problema"]
        tipos_problema[tipo] = tipos_problema.get(tipo, 0) + 1
    
    cols = st.columns(len(tipos_problema))
    emoji_map = {
        "VAZIO": "üî¥",
        "FORMATO": "üü†", 
        "IMPOSS√çVEL": "üü£",
        "FUTURO": "üü°",
        "ANTIGA": "üü§"
    }
    
    for i, (tipo, qtd) in enumerate(tipos_problema.items()):
        with cols[i]:
            emoji = emoji_map.get(tipo, "‚ùå")
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{qtd}</div>
                <div class="metric-label">{emoji} {tipo}</div>
            </div>
            """, unsafe_allow_html=True)
    
    df_problemas = pd.DataFrame(problemas_datas)
    max_linhas_exibir = 50
    
    if len(df_problemas) > max_linhas_exibir:
        df_problemas_exibir = df_problemas.head(max_linhas_exibir)
        st.warning(f"‚ö†Ô∏è **Exibindo apenas as primeiras {max_linhas_exibir} linhas.** Total de problemas: {len(df_problemas)}")
    else:
        df_problemas_exibir = df_problemas
    
    st.dataframe(
        df_problemas_exibir,
        use_container_width=True,
        hide_index=True,
        height=400
    )

def validar_dados_enviados(df):
    """Valida√ß√£o super rigorosa dos dados enviados"""
    erros = []
    avisos = []
    linhas_invalidas_detalhes = []
    
    if df.empty:
        erros.append("‚ùå A planilha est√° vazia")
        return erros, avisos, linhas_invalidas_detalhes
    
    if "LOJA" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'LOJA'")
        avisos.append("üìã Certifique-se de que sua planilha tenha uma coluna chamada 'LOJA'")
    else:
        lojas_validas = df["LOJA"].notna().sum()
        if lojas_validas == 0:
            erros.append("‚ùå Nenhuma loja v√°lida encontrada na coluna 'LOJA'")
        else:
            lojas_unicas = df["LOJA"].dropna().unique()
            if len(lojas_unicas) > 0:
                avisos.append(f"üè™ Lojas encontradas: {', '.join(map(str, lojas_unicas[:5]))}")
                if len(lojas_unicas) > 5:
                    avisos.append(f"... e mais {len(lojas_unicas) - 5} lojas")
    
    if "DATA" not in df.columns:
        erros.append("‚ö†Ô∏è A planilha deve conter uma coluna 'DATA'")
        avisos.append("üìã Lembre-se: o arquivo deve ter uma aba chamada 'Dados' com as colunas 'DATA' e 'LOJA'")
    else:
        problemas_datas = validar_datas_detalhadamente(df)
        
        if problemas_datas:
            erros.append(f"‚ùå {len(problemas_datas)} problemas de data encontrados - CONSOLIDA√á√ÉO BLOQUEADA")
            erros.append("üîß √â OBRIGAT√ìRIO corrigir TODOS os problemas antes de enviar")
            linhas_invalidas_detalhes = problemas_datas
        else:
            avisos.append("‚úÖ Todas as datas est√£o v√°lidas e consistentes!")
    
    return erros, avisos, linhas_invalidas_detalhes

# ===========================
# FUN√á√ïES DE CONSOLIDA√á√ÉO
# ===========================
def baixar_arquivo_consolidado(token):
    """Baixa o arquivo consolidado existente"""
    consolidado_nome = "bonificacao_consolidada.xlsx"
    url = f"https://graph.microsoft.com/v1.0/sites/{SITE_ID}/drives/{DRIVE_ID}/root:/{PASTA_CONSOLIDADO}/{consolidado_nome}:/content"
    headers = {"Authorization": f"Bearer {token}"}
    
    try:
        response = requests.get(url, headers=headers)
        
        if response.status_code == 200:
            df_consolidado = pd.read_excel(BytesIO(response.content))
            df_consolidado.columns = df_consolidado.columns.str.strip().str.upper()
            
            logger.info(f"‚úÖ Arquivo consolidado baixado: {len(df_consolidado)} registros")
            return df_consolidado, True
        else:
            logger.info("üìÑ Arquivo consolidado n√£o existe - ser√° criado novo")
            return pd.DataFrame(), False
            
    except Exception as e:
        logger.error(f"Erro ao baixar arquivo consolidado: {e}")
        return pd.DataFrame(), False

def adicionar_data_ultimo_envio(df_final, lojas_atualizadas):
    """Adiciona/atualiza a coluna DATA_ULTIMO_ENVIO para as lojas que foram atualizadas"""
    try:
        if 'DATA_ULTIMO_ENVIO' not in df_final.columns:
            df_final['DATA_ULTIMO_ENVIO'] = pd.NaT
            logger.info("‚ûï Coluna 'DATA_ULTIMO_ENVIO' criada")
        
        data_atual = datetime.now()
        
        for loja in lojas_atualizadas:
            mask = df_final['LOJA'].astype(str).str.strip().str.upper() == str(loja).strip().upper()
            df_final.loc[mask, 'DATA_ULTIMO_ENVIO'] = data_atual
            
            registros_atualizados = mask.sum()
            logger.info(f"üìÖ Data do √∫ltimo envio atualizada para loja '{loja}': {registros_atualizados} registros")
        
        return df_final
        
    except Exception as e:
        logger.error(f"Erro ao adicionar data do √∫ltimo envio: {e}")
        return df_final

def verificar_seguranca_consolidacao(df_consolidado, df_novo, df_final):
    """Verifica√ß√£o de seguran√ßa cr√≠tica"""
    try:
        lojas_antes = set(df_consolidado['LOJA'].dropna().astype(str).str.strip().str.upper().unique()) if not df_consolidado.empty else set()
        lojas_novas = set(df_novo['LOJA'].dropna().astype(str).str.strip().str.upper().unique())
        lojas_depois = set(df_final['LOJA'].dropna().astype(str).str.strip().str.upper().unique())
        
        logger.info(f"üõ°Ô∏è VERIFICA√á√ÉO DE SEGURAN√áA:")
        logger.info(f"   Lojas ANTES: {lojas_antes}")
        logger.info(f"   Lojas NOVAS: {lojas_novas}")
        logger.info(f"   Lojas DEPOIS: {lojas_depois}")
        
        lojas_esperadas = lojas_antes.union(lojas_novas)
        lojas_perdidas = lojas_esperadas - lojas_depois
        
        if lojas_perdidas:
            error_msg = f"Lojas perdidas durante consolida√ß√£o: {', '.join(lojas_perdidas)}"
            logger.error(f"‚ùå ERRO CR√çTICO: {error_msg}")
            return False, error_msg
        
        for loja in lojas_antes:
            if loja not in lojas_novas:
                if loja not in lojas_depois:
                    error_msg = f"Loja '{loja}' foi removida sem justificativa"
                    logger.error(f"‚ùå ERRO: {error_msg}")
                    return False, error_msg
        
        logger.info(f"‚úÖ VERIFICA√á√ÉO DE SEGURAN√áA PASSOU!")
        return True, f"Verifica√ß√£o passou: {len(lojas_depois)} lojas mantidas"
        
    except Exception as e:
        error_msg = f"Erro durante verifica√ß√£o de seguran√ßa: {str(e)}"
        logger.error(f"‚ùå {error_msg}")
        return False, error_msg

def comparar_e_atualizar_registros(df_consolidado, df_novo):
    """L√≥gica de consolida√ß√£o por LOJA + M√äS/ANO"""
    registros_inseridos = 0
    registros_substituidos = 0
    registros_removidos = 0
    detalhes_operacao = []
    combinacoes_novas = 0
    combinacoes_existentes = 0
    lojas_atualizadas = set()
    
    logger.info(f"üîß INICIANDO CONSOLIDA√á√ÉO:")
    logger.info(f"   Consolidado atual: {len(df_consolidado)} registros")
    logger.info(f"   Novo arquivo: {len(df_novo)} registros")
    
    if df_consolidado.empty:
        df_final = df_novo.copy()
        registros_inseridos = len(df_novo)
        
        lojas_atualizadas = set(df_novo['LOJA'].dropna().astype(str).str.strip().str.upper().unique())
        
        df_temp = df_novo.copy()
        df_temp['mes_ano'] = df_temp['DATA'].dt.to_period('M')
        combinacoes_unicas = df_temp.groupby(['LOJA', 'mes_ano']).size()
        combinacoes_novas = len(combinacoes_unicas)
        
        logger.info(f"‚úÖ PRIMEIRA CONSOLIDA√á√ÉO: {registros_inseridos} registros inseridos")
        
        for _, row in df_novo.iterrows():
            detalhes_operacao.append({
                "Opera√ß√£o": "INSERIDO",
                "Loja": row["LOJA"],
                "M√™s/Ano": row["DATA"].strftime("%m/%Y"),
                "Data": row["DATA"].strftime("%d/%m/%Y"),
                "Motivo": "Primeira consolida√ß√£o - arquivo vazio"
            })
        
        df_final = adicionar_data_ultimo_envio(df_final, lojas_atualizadas)
        
        return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes
    
    colunas = df_novo.columns.tolist()
    for col in colunas:
        if col not in df_consolidado.columns:
            df_consolidado[col] = None
            logger.info(f"‚ûï Coluna '{col}' adicionada ao consolidado")
    
    df_final = df_consolidado.copy()
    
    df_novo_temp = df_novo.copy()
    df_novo_temp['mes_ano'] = df_novo_temp['DATA'].dt.to_period('M')
    
    df_final_temp = df_final.copy()
    df_final_temp['mes_ano'] = df_final_temp['DATA'].dt.to_period('M')
    
    grupos_novos = df_novo_temp.groupby(['LOJA', 'mes_ano'])
    
    logger.info(f"üìä Processando {len(grupos_novos)} combina√ß√µes √∫nicas de Loja+M√™s/Ano")
    
    for (loja, periodo_grupo), grupo_df in grupos_novos:
        if pd.isna(loja) or str(loja).strip() == '':
            logger.warning(f"‚ö†Ô∏è Pulando loja inv√°lida: {loja}")
            continue
        
        lojas_atualizadas.add(str(loja).strip().upper())
        
        logger.info(f"üîç Processando: '{loja}' em {periodo_grupo} ({len(grupo_df)} registros)")
        
        mask_existente = (
            (df_final_temp["mes_ano"] == periodo_grupo) &
            (df_final_temp["LOJA"].astype(str).str.strip().str.upper() == str(loja).strip().upper())
        )
        
        registros_existentes = df_final[mask_existente]
        
        if not registros_existentes.empty:
            num_removidos = len(registros_existentes)
            
            logger.info(f"   üîÑ SUBSTITUI√á√ÉO: Removendo {num_removidos} registros antigos do per√≠odo {periodo_grupo}")
            
            df_final = df_final[~mask_existente]
            df_final_temp = df_final_temp[~mask_existente]
            
            registros_removidos += num_removidos
            combinacoes_existentes += 1
            
            detalhes_operacao.append({
                "Opera√ß√£o": "REMOVIDO",
                "Loja": loja,
                "M√™s/Ano": periodo_grupo.strftime("%m/%Y"),
                "Data": f"Todo o per√≠odo {periodo_grupo}",
                "Motivo": f"Substitui√ß√£o: {num_removidos} registro(s) antigo(s) removido(s)"
            })
            
            registros_substituidos += len(grupo_df)
            operacao_tipo = "SUBSTITU√çDO"
            motivo = f"Substitui√ß√£o completa do per√≠odo: {len(grupo_df)} novo(s) registro(s)"
            
        else:
            logger.info(f"   ‚ûï NOVA COMBINA√á√ÉO: Adicionando {len(grupo_df)} registros para {periodo_grupo}")
            registros_inseridos += len(grupo_df)
            combinacoes_novas += 1
            operacao_tipo = "INSERIDO"
            motivo = f"Nova combina√ß√£o: {len(grupo_df)} registro(s) inserido(s)"
        
        grupo_para_inserir = grupo_df.drop(columns=['mes_ano'], errors='ignore')
        df_final = pd.concat([df_final, grupo_para_inserir], ignore_index=True)
        df_final_temp = pd.concat([df_final_temp, grupo_df], ignore_index=True)
        
        detalhes_operacao.append({
            "Opera√ß√£o": operacao_tipo,
            "Loja": loja,
            "M√™s/Ano": periodo_grupo.strftime("%m/%Y"),
            "Data": f"Per√≠odo {periodo_grupo}",
            "Motivo": motivo
        })
    
    df_final = adicionar_data_ultimo_envio(df_final, lojas_atualizadas)
    
    logger.info(f"üéØ CONSOLIDA√á√ÉO FINALIZADA:")
    logger.info(f"   Registros inseridos: {registros_inseridos}")
    logger.info(f"   Registros substitu√≠dos: {registros_substituidos}")
    logger.info(f"   Registros removidos: {registros_removidos}")
    logger.info(f"   Total final: {len(df_final)} registros")
    
    return df_final, registros_inseridos, registros_substituidos, registros_removidos, detalhes_operacao, combinacoes_novas, combinacoes_existentes

def salvar_arquivo_enviado(df_novo, nome_arquivo_original, token):
    """Salva uma c√≥pia do arquivo enviado na pasta de backups"""
    try:
        timestamp = datetime.now().strftime("%Y-%m-%d_%Hh%M")
        nome_base = nome_arquivo_original.replace(".xlsx", "").replace(".xls", "")
        nome_arquivo_backup = f"{nome_base}_enviado_{timestamp}.xlsx"
        
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df_novo.to_excel(writer, index=False, sheet_name="Dados")
        buffer.seek(0)
        
        sucesso, status_code, resposta = upload_onedrive(nome_arquivo_backup, buffer.read(), token, "backup")
        
        if sucesso:
            logger.info(f"üíæ Arquivo enviado salvo como backup: {nome_arquivo_backup}")
        else:
            logger.warning(f"‚ö†Ô∏è N√£o foi poss√≠vel salvar backup do arquivo enviado: {status_code}")
            
    except Exception as e:
        logger.error(f"Erro ao salvar arquivo enviado: {e}")

def analise_pre_consolidacao(df_consolidado, df_novo):
    """An√°lise pr√©-consolida√ß√£o"""
    try:
        st.markdown("### üìä An√°lise Pr√©-Consolida√ß√£o")
        
        df_novo_temp = df_novo.copy()
        df_novo_temp['mes_ano'] = df_novo_temp['DATA'].dt.to_period('M')
        
        lojas_novas = set(df_novo['LOJA'].dropna().astype(str).str.strip().str.upper().unique())
        
        if not df_consolidado.empty:
            df_consolidado_temp = df_consolidado.copy()
            df_consolidado_temp['mes_ano'] = df_consolidado_temp['DATA'].dt.to_period('M')
        
        combinacoes_novas = []
        combinacoes_existentes = []
        
        grupos_novos = df_novo_temp.groupby(['LOJA', 'mes_ano'])
        
        for (loja, periodo), grupo in grupos_novos:
            if pd.isna(loja):
                continue
                
            loja_upper = str(loja).strip().upper()
            
            if not df_consolidado.empty:
                mask_existente = (
                    (df_consolidado_temp["mes_ano"] == periodo) &
                    (df_consolidado_temp["LOJA"].astype(str).str.strip().str.upper() == loja_upper)
                )
                
                if mask_existente.any():
                    combinacoes_existentes.append({
                        "Loja": loja,
                        "Per√≠odo": periodo.strftime("%m/%Y"),
                        "Novos Registros": len(grupo),
                        "Registros Existentes": mask_existente.sum()
                    })
                else:
                    combinacoes_novas.append({
                        "Loja": loja,
                        "Per√≠odo": periodo.strftime("%m/%Y"),
                        "Registros": len(grupo)
                    })
            else:
                combinacoes_novas.append({
                    "Loja": loja,
                    "Per√≠odo": periodo.strftime("%m/%Y"),
                    "Registros": len(grupo)
                })
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(lojas_novas)}</div>
                <div class="metric-label">Lojas</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col2:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(df_novo)}</div>
                <div class="metric-label">Registros Novos</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col3:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(combinacoes_novas)}</div>
                <div class="metric-label">Novos Per√≠odos</div>
            </div>
            """, unsafe_allow_html=True)
        
        with col4:
            st.markdown(f"""
            <div class="metric-container">
                <div class="metric-value">{len(combinacoes_existentes)}</div>
                <div class="metric-label">Per√≠odos Atualizados</div>
            </div>
            """, unsafe_allow_html=True)
        
        if combinacoes_novas:
            with st.expander("‚ûï Novos Per√≠odos que ser√£o Adicionados"):
                df_novas = pd.DataFrame(combinacoes_novas)
                st.dataframe(df_novas, use_container_width=True, hide_index=True)
        
        if combinacoes_existentes:
            with st.expander("üîÑ Per√≠odos que ser√£o Substitu√≠dos"):
                df_existentes = pd.DataFrame(combinacoes_existentes)
                st.dataframe(df_existentes, use_container_width=True, hide_index=True)
        
        return True
        
    except Exception as e:
        logger.error(f"Erro na an√°lise pr√©-consolida√ß√£o: {e}")
        st.error(f"‚ùå Erro na an√°lise: {str(e)}")
        return False

def processar_consolidacao_com_lock(df_novo, nome_arquivo, token):
    """Consolida√ß√£o com sistema de lock"""
    session_id = gerar_id_sessao()
    
    status_container = st.empty()
    progress_container = st.empty()
    
    try:
        status_container.markdown("""
        <div class="custom-alert info">
            <h4>üîÑ Iniciando processo de consolida√ß√£o...</h4>
        </div>
        """, unsafe_allow_html=True)
        
        sistema_ocupado, lock_data = verificar_lock_existente(token)
        if sistema_ocupado:
            status_container.markdown("""
            <div class="custom-alert error">
                <h4>üîí Sistema ocupado! Outro usu√°rio est√° fazendo consolida√ß√£o.</h4>
            </div>
            """, unsafe_allow_html=True)
            return False
        
        progress_container.progress(10)
        
        lock_criado, session_lock = criar_lock(token, "Consolida√ß√£o de bonifica√ß√µes")
        
        if not lock_criado:
            status_container.markdown("""
            <div class="custom-alert error">
                <h4>‚ùå N√£o foi poss√≠vel bloquear o sistema. Tente novamente.</h4>
            </div>
            """, unsafe_allow_html=True)
            return False
        
        progress_container.progress(15)
        
        atualizar_status_lock(token, session_lock, "BAIXANDO_ARQUIVO", "Baixando arquivo consolidado")
        progress_container.progress(25)
        
        df_consolidado, arquivo_existe = baixar_arquivo_consolidado(token)
        progress_container.progress(35)

        atualizar_status_lock(token, session_lock, "PREPARANDO_DADOS", "Validando e preparando dados")
        
        df_novo = df_novo.copy()
        df_novo.columns = df_novo.columns.str.strip().str.upper()
        
        df_novo["DATA"] = pd.to_datetime(df_novo["DATA"], errors="coerce")
        linhas_invalidas = df_novo["DATA"].isna().sum()
        df_novo = df_novo.dropna(subset=["DATA"])

        if df_novo.empty:
            status_container.markdown("""
            <div class="custom-alert error">
                <h4>‚ùå Nenhum registro v√°lido para consolidar</h4>
            </div>
            """, unsafe_allow_html=True)
            remover_lock(token, session_lock)
            return False

        progress_container.progress(45)

        analise_ok = analise_pre_consolidacao(df_consolidado, df_novo)
        
        if not analise_ok:
            remover_lock(token, session_lock)
            return False
        
        progress_container.progress(55)

        atualizar_status_lock(token, session_lock, "CONSOLIDANDO", f"Processando {len(df_novo)} registros por m√™s/ano")
        progress_container.progress(65)
        
        df_final, inseridos, substituidos, removidos, detalhes, novas_combinacoes, combinacoes_existentes = comparar_e_atualizar_registros(
            df_consolidado, df_novo
        )
        
        progress_container.progress(75)

        verificacao_ok, msg_verificacao = verificar_seguranca_consolidacao(df_consolidado, df_novo, df_final)
        
        if not verificacao_ok:
            status_container.markdown(f"""
            <div class="custom-alert error">
                <h4>‚ùå ERRO DE SEGURAN√áA: {msg_verificacao}</h4>
            </div>
            """, unsafe_allow_html=True)
            remover_lock(token, session_lock)
            return False

        df_final = df_final.sort_values(["DATA", "LOJA"], na_position='last').reset_index(drop=True)
        progress_container.progress(80)
        
        salvar_arquivo_enviado(df_novo, nome_arquivo, token)
        progress_container.progress(85)
        
        atualizar_status_lock(token, session_lock, "UPLOAD_FINAL", "Salvando arquivo consolidado")
        
        buffer = BytesIO()
        with pd.ExcelWriter(buffer, engine='openpyxl') as writer:
            df_final.to_excel(writer, index=False, sheet_name="Dados")
        buffer.seek(0)
        
        consolidado_nome = "bonificacao_consolidada.xlsx"
        sucesso, status_code, resposta = upload_onedrive(consolidado_nome, buffer.read(), token, "consolidado")

        progress_container.progress(95)

        remover_lock(token, session_lock)
        progress_container.progress(100)
        
        if sucesso:
            status_container.empty()
            progress_container.empty()
            
            st.markdown("""
            <div class="custom-alert success">
                <h2>üéâ CONSOLIDA√á√ÉO REALIZADA COM SUCESSO!</h2>
                <p>üîì Sistema liberado e dispon√≠vel para outros usu√°rios</p>
            </div>
            """, unsafe_allow_html=True)
            
            with st.expander("üìÅ Localiza√ß√£o dos Arquivos", expanded=True):
                col1, col2 = st.columns(2)
                with col1:
                    st.info(f"üìä **Arquivo Consolidado:**\n`{PASTA_CONSOLIDADO}/bonificacao_consolidada.xlsx`")
                with col2:
                    st.info(f"üíæ **Backups e Envios:**\n`{PASTA_ENVIOS_BACKUPS}/`")
            
            st.markdown("### üìà **Resultado da Consolida√ß√£o**")
            col1, col2, col3, col4 = st.columns(4)
            
            with col1:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{len(df_final):,}</div>
                    <div class="metric-label">üìä Total Final</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col2:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{inseridos}</div>
                    <div class="metric-label">‚ûï Inseridos</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col3:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{substituidos}</div>
                    <div class="metric-label">üîÑ Substitu√≠dos</div>
                </div>
                """, unsafe_allow_html=True)
            
            with col4:
                st.markdown(f"""
                <div class="metric-container">
                    <div class="metric-value">{removidos}</div>
                    <div class="metric-label">üóëÔ∏è Removidos</div>
                </div>
                """, unsafe_allow_html=True)
            
            if novas_combinacoes > 0 or combinacoes_existentes > 0:
                st.markdown("### üìà **An√°lise de Combina√ß√µes (Loja + M√™s/Ano)**")
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    st.markdown(f"""
                    <div class="metric-container">
                        <div class="metric-value">{novas_combinacoes}</div>
                        <div class="metric-label">üÜï Novos Per√≠odos</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col2:
                    st.markdown(f"""
                    <div class="metric-container">
                        <div class="metric-value">{combinacoes_existentes}</div>
                        <div class="metric-label">üîÑ Per√≠odos Atualizados</div>
                    </div>
                    """, unsafe_allow_html=True)
                
                with col3:
                    total_processadas = novas_combinacoes + combinacoes_existentes
                    st.markdown(f"""
                    <div class="metric-container">
                        <div class="metric-value">{total_processadas}</div>
                        <div class="metric-label">üìä Total Processado</div>
                    </div>
                    """, unsafe_allow_html=True)
            
            if 'DATA_ULTIMO_ENVIO' in df_final.columns:
                st.markdown("""
                <div class="custom-alert success">
                    <h4>üìÖ Campo "Data do √öltimo Envio" atualizado!</h4>
                    <p>A planilha consolidada inclui a data do √∫ltimo envio para cada loja</p>
                </div>
                """, unsafe_allow_html=True)
            
            if detalhes:
                with st.expander("üìã Detalhes das Opera√ß√µes", expanded=False):
                    df_detalhes = pd.DataFrame(detalhes)
                    st.dataframe(df_detalhes, use_container_width=True, hide_index=True)
            
            if not df_final.empty:
                resumo_lojas = df_final.groupby("LOJA").agg({
                    "DATA": ["count", "min", "max"]
                }).round(0)
                
                resumo_lojas.columns = ["Total Registros", "Data Inicial", "Data Final"]
                resumo_lojas["Data Inicial"] = pd.to_datetime(resumo_lojas["Data Inicial"]).dt.strftime("%d/%m/%Y")
                resumo_lojas["Data Final"] = pd.to_datetime(resumo_lojas["Data Final"]).dt.strftime("%d/%m/%Y")
                
                if 'DATA_ULTIMO_ENVIO' in df_final.columns:
                    ultimo_envio = df_final.groupby("LOJA")["DATA_ULTIMO_ENVIO"].max()
                    ultimo_envio = ultimo_envio.dt.strftime("%d/%m/%Y %H:%M")
                    resumo_lojas["√öltimo Envio"] = ultimo_envio
                
                with st.expander("üè™ Resumo por Loja"):
                    st.dataframe(resumo_lojas, use_container_width=True)
            
            return True
        else:
            status_container.markdown(f"""
            <div class="custom-alert error">
                <h4>‚ùå Erro no upload: Status {status_code}</h4>
            </div>
            """, unsafe_allow_html=True)
            return False
            
    except Exception as e:
        logger.error(f"Erro na consolida√ß√£o: {e}")
        remover_lock(token, session_id, force=True)
        
        status_container.markdown(f"""
        <div class="custom-alert error">
            <h4>‚ùå Erro durante consolida√ß√£o: {str(e)}</h4>
        </div>
        """, unsafe_allow_html=True)
        progress_container.empty()
        return False

# ===========================
# INTERFACE STREAMLIT
# ===========================
def main():
    st.set_page_config(
        page_title=f"Sistema de Bonifica√ß√µes v{APP_VERSION}", 
        layout="wide",
        initial_sidebar_state="expanded"
    )

    aplicar_estilos_css()

    st.markdown(f"""
    <div class="main-header fade-in">
        <div style="display: flex; justify-content: space-between; align-items: center;">
            <div>
                <h1>üéÅ Sistema de Consolida√ß√£o de Bonifica√ß√µes</h1>
                <p style="margin: 0.5rem 0 0 0; opacity: 0.9;">Upload e consolida√ß√£o autom√°tica por Loja + M√™s/Ano</p>
            </div>
            <div class="version-badge">
                <strong>v{APP_VERSION}</strong><br>
                <small>{VERSION_DATE}</small>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    st.sidebar.markdown("### üì§ Upload de Bonifica√ß√µes")
    st.sidebar.divider()
    st.sidebar.markdown("**Status do Sistema:**")
    
    token = obter_token()
    if not token:
        st.sidebar.error("‚ùå Desconectado")
        st.error("‚ùå N√£o foi poss√≠vel autenticar. Verifique as credenciais.")
        st.stop()
    else:
        st.sidebar.success("‚úÖ Conectado")

    st.markdown("## üîí Status do Sistema")
    
    sistema_ocupado = exibir_status_sistema(token)
    
    if sistema_ocupado:
        st.markdown("---")
        st.info("üîÑ Esta p√°gina ser√° atualizada automaticamente a cada 15 segundos")
        time.sleep(15)
        st.rerun()

    st.divider()

    with st.sidebar.expander("‚ÑπÔ∏è Informa√ß√µes do Sistema"):
        st.markdown(f"**Vers√£o:** {APP_VERSION}")
        st.markdown(f"**Data:** {VERSION_DATE}")
        st.markdown(f"**Consolidado:** `bonificacao_consolidada.xlsx`")
        st.markdown(f"**Pasta:** `{PASTA_CONSOLIDADO}`")

    st.markdown("## üì§ Upload de Planilha Excel")
    
    if sistema_ocupado:
        st.markdown("""
        <div class="custom-alert warning">
            <h4>‚ö†Ô∏è Upload desabilitado - Sistema em uso por outro usu√°rio</h4>
        </div>
        """, unsafe_allow_html=True)
        
        if st.button("üîÑ Verificar Status Novamente"):
            st.rerun()
        
        return
    
    st.markdown("""
    <div class="custom-alert info">
        <h4>üí° Importante</h4>
        <p>A planilha deve ter uma aba 'Dados' com as colunas 'LOJA' e 'DATA'</p>
    </div>
    """, unsafe_allow_html=True)
    
    with st.expander("üéØ Como funciona a consolida√ß√£o", expanded=True):
        st.markdown("### üè™ **Consolida√ß√£o por LOJA + M√äS/ANO:**")
        st.info("‚úÖ Substitui dados mensais existentes da mesma loja")
        st.info("‚úÖ Adiciona novos per√≠odos mensais")
        st.info("‚úÖ Mant√©m dados de outras lojas intactos")
        st.info("‚úÖ Registra data do √∫ltimo envio por loja")
        st.info("‚úÖ Cria backups autom√°ticos")
    
    st.divider()

    uploaded_file = st.file_uploader(
        "Escolha um arquivo Excel", 
        type=["xlsx", "xls"],
        help="Formatos aceitos: .xlsx, .xls"
    )

    df = None
    if uploaded_file:
        try:
            st.markdown(f"""
            <div class="custom-alert success">
                <h4>üìÅ Arquivo carregado: {uploaded_file.name}</h4>
            </div>
            """, unsafe_allow_html=True)
            
            with st.spinner("üìñ Lendo arquivo..."):
                xls = pd.ExcelFile(uploaded_file)
                sheets = xls.sheet_names
                
                if "Dados" in sheets:
                    sheet = "Dados"
                    st.success("‚úÖ Aba 'Dados' encontrada automaticamente")
                else:
                    sheet = st.selectbox("Selecione a aba:", sheets)
                    if sheet != "Dados":
                        st.warning("‚ö†Ô∏è Recomendamos usar uma aba chamada 'Dados'")
                
                df = pd.read_excel(uploaded_file, sheet_name=sheet)
                df.columns = df.columns.str.strip().str.upper()
                
                st.success(f"‚úÖ Dados carregados: {len(df)} linhas, {len(df.columns)} colunas")
                
                with st.expander("üëÄ Preview dos Dados", expanded=True):
                    st.dataframe(df.head(10), use_container_width=True)
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.markdown(f"""
                        <div class="metric-container">
                            <div class="metric-value">{len(df)}</div>
                            <div class="metric-label">Linhas</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col2:
                        st.markdown(f"""
                        <div class="metric-container">
                            <div class="metric-value">{len(df.columns)}</div>
                            <div class="metric-label">Colunas</div>
                        </div>
                        """, unsafe_allow_html=True)
                    
                    with col3:
                        if "LOJA" in df.columns:
                            lojas_unicas = df["LOJA"].dropna().nunique()
                            st.markdown(f"""
                            <div class="metric-container">
                                <div class="metric-value">{lojas_unicas}</div>
                                <div class="metric-label">Lojas</div>
                            </div>
                            """, unsafe_allow_html=True)
                
        except Exception as e:
            st.error(f"‚ùå Erro ao ler arquivo: {str(e)}")
            st.stop()

    if df is not None:
        st.markdown("### üîç Valida√ß√£o dos Dados")
        
        with st.spinner("üîç Validando dados..."):
            erros, avisos, problemas_datas = validar_dados_enviados(df)
        
        if erros:
            st.markdown("""
            <div class="custom-alert error">
                <h4>‚ùå Problemas Encontrados</h4>
            </div>
            """, unsafe_allow_html=True)
            
            for erro in erros:
                st.error(erro)
            
            if problemas_datas:
                exibir_problemas_datas(problemas_datas)
            
            botao_desabilitado = True
        else:
            st.markdown("""
            <div class="custom-alert success">
                <h4>‚úÖ Valida√ß√£o Aprovada</h4>
            </div>
            """, unsafe_allow_html=True)
            botao_desabilitado = False
        
        if avisos:
            for aviso in avisos:
                st.info(aviso)
        
        st.divider()
        
        if not erros:
            col1, col2 = st.columns([2, 1])
            
            with col1:
                if botao_desabilitado:
                    st.button("‚ùå Consolidar Dados", type="primary", disabled=True)
                else:
                    if st.button("‚úÖ **Consolidar Dados**", type="primary"):
                        st.markdown("""
                        <div class="custom-alert warning">
                            <h4>‚è≥ Consolida√ß√£o iniciada! N√ÉO feche esta p√°gina!</h4>
                        </div>
                        """, unsafe_allow_html=True)
                        
                        sucesso = processar_consolidacao_com_lock(df, uploaded_file.name, token)
                        
                        if sucesso:
                            st.balloons()
            
            with col2:
                if st.button("üîÑ Limpar Tela", type="secondary"):
                    st.rerun()

    st.markdown("---")
    st.markdown(f"""
    <div style="text-align: center; padding: 2rem; background: #f8f9fa; border-radius: 12px;">
        <strong>üéÅ Sistema de Consolida√ß√£o de Bonifica√ß√µes v{APP_VERSION}</strong><br>
        <small>√öltima atualiza√ß√£o: {VERSION_DATE}</small>
    </div>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()
